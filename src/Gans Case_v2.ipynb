{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5f31fd-f9f7-46d8-9d14-25bc2ebb7c60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\lertora\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lertora\\anaconda3\\lib\\site-packages (from sqlalchemy) (2.0.1)\n",
      "Requirement already satisfied: pymysql in c:\\users\\lertora\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# install all needed libraries\n",
    "!pip install sqlalchemy\n",
    "!pip install pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78ec023-9989-467a-ad8f-1fa18e635fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Exctracting a list of the biggest european cities\n",
    "\n",
    "url_loop = \"https://en.wikipedia.org/wiki/List_of_cities_in_the_European_Union_by_population_within_city_limits\"\n",
    "\n",
    "response = requests.get(url_loop)\n",
    "\n",
    "original_soup_cities = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#Limiting data to the Y-Axis\n",
    "side_table_cities = original_soup_cities.find(\"tbody\")\n",
    "    \n",
    "list_cities = side_table_cities.find_all(width=\"23\")\n",
    "\n",
    "#Creating list of cities\n",
    "list_cities_extract = []\n",
    "for i in range(len(list_cities)):\n",
    "    list_cities_extract.append(list_cities[i].find_previous(\"a\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063de664-5ea6-4a79-ac4b-73befc666cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#First, I will create all needed functions, second step will be to store information correctly in the DataFrames, \n",
    "#and as third step reflecting it into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab96aa2-e4e3-4e60-9c1b-d619244edf4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_name = []\n",
    "population = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "country = []\n",
    "date_forecast = []\n",
    "temperature = []\n",
    "forecast = []\n",
    "rain_in_last_3h = []\n",
    "wind_speed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca97f5e-0ea5-47f2-92e3-c4ef9a83f0ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cities : Function for Web Scraping population, latitude, country\n",
    "def cities(example):\n",
    "    \"\"\"\n",
    "    Scrapes information from Wikipedia about a city and appends the data to global lists.\n",
    "\n",
    "    Parameters:\n",
    "    - example (str): The name of the city to fetch information for.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Global Lists Modified:\n",
    "    - city_name (list): List of city names.\n",
    "    - population (list): List of city populations.\n",
    "    - latitude (list): List of city latitudes.\n",
    "    - longitude (list): List of city longitudes.\n",
    "    - country (list): List of city countries.\n",
    "    \"\"\"\n",
    "\n",
    "    # Exit early if the city is already in the list\n",
    "    if example in city_name:\n",
    "        return\n",
    "    \n",
    "    # Append the city name to the global list\n",
    "    city_name.append(example)\n",
    "    \n",
    "    # Replace spaces with underscores in the city name for constructing the Wikipedia URL\n",
    "    example = example.replace(\" \", \"_\")\n",
    "    \n",
    "    # Construct the Wikipedia URL for the city\n",
    "    url_loop = f\"https://en.wikipedia.org/wiki/{example}\"\n",
    "\n",
    "    # Make a request to the Wikipedia page\n",
    "    response = requests.get(url_loop)\n",
    "\n",
    "    # Parse the HTML content of the Wikipedia page\n",
    "    original_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract information from the infobox if it exists on the Wikipedia page\n",
    "    side_table = original_soup.find(\"table\", class_=\"infobox ib-settlement vcard\")\n",
    "\n",
    "    if side_table:\n",
    "        # Extract population information\n",
    "        population_value = side_table.find(string=re.compile(\"population\", re.IGNORECASE))\n",
    "        try:\n",
    "            population.append(int(population_value.find_next(\"td\").get_text().replace(\",\", \"\")) if population_value else None)\n",
    "        except (ValueError, AttributeError):\n",
    "            population.append(None)\n",
    "\n",
    "        # Extract latitude information\n",
    "        latitude_value = side_table.find(class_=\"latitude\")\n",
    "        latitude.append(latitude_value.get_text() if latitude_value else None)\n",
    "        \n",
    "        # Extract longitude information\n",
    "        longitude_value = side_table.find(class_=\"longitude\")\n",
    "        longitude.append(longitude_value.get_text() if longitude_value else None)\n",
    "\n",
    "        # Extract country information\n",
    "        country_value = side_table.find(string=re.compile(\"country\", re.IGNORECASE))\n",
    "        country.append(country_value.find_next(\"td\").get_text() if country_value else None)\n",
    "    else:\n",
    "        # If the table is not found, set NaN values for all fields\n",
    "        population.append(None)\n",
    "        latitude.append(None)\n",
    "        longitude.append(None)\n",
    "        country.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3a82bc-e48c-44b8-987d-71d4597fabb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Applying function \"Cities\" to this new list\n",
    "for i in list_cities_extract:\n",
    "    cities(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c20fd32-98a2-4bba-915f-9a69bfb205a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Changing coordinates to decimals\n",
    "import re\n",
    "\n",
    "\"\"\"\n",
    "Convert coordinates in degrees, minutes, and seconds (DMS) format to decimal degrees (DD).\n",
    "\n",
    "Parameters:\n",
    "- coord_str (str): String representation of coordinates in DMS format, e.g., '34°25′12″N'.\n",
    "\n",
    "Returns:\n",
    "float: Decimal degrees representation of the coordinates.\n",
    "\n",
    "Raises:\n",
    "ValueError: If the coordinate format is invalid.\n",
    "\n",
    "Example:\n",
    ">>> dms_to_dd('34°25′12″N')\n",
    "34.42\n",
    "\"\"\"\n",
    "\n",
    "def dms_to_dd(coord_str):\n",
    "    # Remove letters \"W\", \"S\", \"N\", or \"E\"\n",
    "    coord_str = re.sub(r'[WwSsNnEe]', '', coord_str)\n",
    "    \n",
    "    # Regular expression to extract degrees, optional minutes, and optional seconds\n",
    "    pattern = re.compile(r'(\\d+)°(?:(\\d+)′)?(?:(\\d+)″)?')\n",
    "    match = pattern.match(coord_str)\n",
    "    \n",
    "    if match:\n",
    "        degrees, minutes, seconds = map(int, match.groups(default='0'))\n",
    "        dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "        \n",
    "        return dd\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid coordinate format: {coord_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409936b4-6af8-4f0e-b067-fb6b375b6a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Extracting a list of cars per country from a Wikipedia catalog (Total = 150 entries)\n",
    "def country_cars():\n",
    "    url_loop = \"https://en.wikipedia.org/wiki/List_of_countries_by_vehicles_per_capita\"\n",
    "\n",
    "    response = requests.get(url_loop)\n",
    "\n",
    "    original_soup_autos = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    #Limiting data to the Y-Axis\n",
    "    side_table_autos = original_soup_autos.find(\"tbody\")\n",
    "    \n",
    "    list_countries = side_table_autos.find_all(\"span\", class_=\"flagicon\")\n",
    "    \n",
    "    #Creating list of countries and amount of vehicles\n",
    "    list_countries_extract = []\n",
    "    list_countries_extract_autos = []\n",
    "    for i in range(len(list_countries)):\n",
    "        list_countries_extract.append(list_countries[i].find_next(\"a\").get_text())\n",
    "        list_countries_extract_autos.append(list_countries[i].find_next(\"td\").find_next(\"td\").get_text())\n",
    "    for n in range(len(list_countries_extract_autos)):\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\",\",\"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"\\n\",\"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"[\",\"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"]\",\"\")\n",
    "        list_countries_extract_autos[n] = int(list_countries_extract_autos[n])\n",
    "        \n",
    "    countries_df = pd.DataFrame({\"country\":list_countries_extract, \"cars\":list_countries_extract_autos})\n",
    "    return countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b915dbf-9f38-4e59-a829-6ab2f2b561eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_df = country_cars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98127f67-cbd6-4874-b76e-25ff5db834dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Next step is to create the function that gets:\n",
    "#1) Name of the city using latitude and longitude\n",
    "#2) Weather forecast in each city of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed1b24c-06b7-40b0-a3ff-db71868d69dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weather_request(example):\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    weather_items = []\n",
    "    latitude = information_df.loc[information_df[\"city_name\"] == example, \"latitude\"].values[0]\n",
    "    longitude = information_df.loc[information_df[\"city_name\"] == example, \"longitude\"].values[0]\n",
    "\n",
    "    # Construct the API request URL\n",
    "    url_map = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid=4bcaab846859609d453e249b3b3f0a16\"\n",
    "    \n",
    "    # Make the API request and handle potential errors\n",
    "    try:\n",
    "        city_id_openweather = requests.get(url_map)\n",
    "        city_id_openweather.raise_for_status()  # Raise an error for bad responses (non-2xx status codes)\n",
    "        city_id_openweather = city_id_openweather.json()\n",
    "        city_id_openweather = city_id_openweather[\"id\"]\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle request exceptions (e.g., network issues, API errors)\n",
    "        print(f\"Error in request for latitude {latitude}, longitude {longitude}: {e}\")\n",
    "        temperature_request = None  # Append None for temperature to indicate an error\n",
    "        sky_request = None  # Append None for sky description to indicate an error\n",
    "    \n",
    "    url = f\"http://api.openweathermap.org/data/2.5/forecast?id={city_id_openweather}&appid=4bcaab846859609d453e249b3b3f0a16\"\n",
    " \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    response = response.json()\n",
    "    \n",
    "    for item in response[\"list\"]:\n",
    "        weather_item = {\n",
    "        \"city_name\" : example,\n",
    "        \"forecast_time\": item.get(\"dt_txt\", None),\n",
    "        \"temperature\": item[\"main\"].get(\"temp\", None),\n",
    "        \"forecast\": item[\"weather\"][0].get(\"main\", None),\n",
    "        \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n",
    "        \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n",
    "        \"retrieval_time\" : retrieval_time\n",
    "        }\n",
    "        \n",
    "        weather_items.append(weather_item)\n",
    "        weather_df = pd.DataFrame(weather_items)\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1f7d5c-84ff-430e-a82f-d6975fd79d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Next step will be to create the functions to push DataFrames into SQL\n",
    "def connection():\n",
    "  schema = \"gans\"\n",
    "  host = \"127.0.0.1\"\n",
    "  user = \"root\"\n",
    "  password = \"Riverplate121.\"\n",
    "  port = 3306\n",
    "  return f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc0c907-213c-496a-ad70-32b045cdf0d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cities_data(connection_string):\n",
    "  return pd.read_sql(\"cities\", con=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "491c661d-ca99-4d6d-a6d6-5205ddd61d08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'city_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m information_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 2\u001b[0m retreiving_and_sending_data()\n",
      "Cell \u001b[1;32mIn[43], line 82\u001b[0m, in \u001b[0;36mretreiving_and_sending_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m weather_df_final \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m city \u001b[38;5;129;01min\u001b[39;00m information_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m weather_request(city)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Check if result is not empty before concatenating\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mempty:\n",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m, in \u001b[0;36mweather_request\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      3\u001b[0m retrieval_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow(berlin_timezone)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m weather_items \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m latitude \u001b[38;5;241m=\u001b[39m information_df\u001b[38;5;241m.\u001b[39mloc[information_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m example, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m longitude \u001b[38;5;241m=\u001b[39m information_df\u001b[38;5;241m.\u001b[39mloc[information_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcity_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m example, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Construct the API request URL\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:349\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'city_name'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14d76508-942e-4b32-aab3-1c0ab401e5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retreiving_and_sending_data():\n",
    "    connection_string=connection()\n",
    "    #First step is to create send and retrieve Countries, therefore a new Dataframe needs to be created:\n",
    "    countries_list_df = countries_df.loc[:,\"country\"].reset_index().drop(\"index\",axis=1)\n",
    "    #Second step is to send this data to sql and retrieve it to merge it\n",
    "    countries_list_df.to_sql('countries',\n",
    "                      if_exists='append',\n",
    "                      con=connection_string,\n",
    "                      index=False,\n",
    "                        )\n",
    "    countries_from_sql = get_countries_data(connection_string)\n",
    "    #Now with the IDs, cars tables can be merged, and pushed into SQL as well\n",
    "    cars = countries_from_sql.merge(countries_df,\n",
    "                             on=\"country\",\n",
    "                             how=\"left\")\n",
    "    cars_df = cars.drop([\"country\"],axis = 1)\n",
    "    cars_df.to_sql('cars',\n",
    "                      if_exists='append',\n",
    "                      con=connection_string,\n",
    "                      index=False,\n",
    "                  )\n",
    "    \n",
    "    #Same work has to be done with cities, information and weather\n",
    "    for i in list_cities_extract:\n",
    "        cities(i)\n",
    "    \n",
    "    #First we will create the DataFrame and erase all NaN rows\n",
    "    information_df = pd.DataFrame({\"city_name\": city_name, \"population\": population, \"latitude\": latitude, \"longitude\": longitude, \"country\": country})\n",
    "    information_df = information_df.loc[information_df[\"population\"].notnull()&information_df[\"latitude\"].notnull()&information_df[\"longitude\"].notnull(),:]\n",
    "    \n",
    "    latitude_decimal = []\n",
    "    for i in information_df[\"latitude\"]:\n",
    "        latitude_decimal.append(dms_to_dd(i))\n",
    "\n",
    "    longitude_decimal =[]\n",
    "    for n in information_df[\"longitude\"]:\n",
    "        longitude_decimal.append(dms_to_dd(n))\n",
    "    \n",
    "    information_df[\"latitude\"] = latitude_decimal\n",
    "    information_df[\"longitude\"] = longitude_decimal\n",
    "    \n",
    "    \n",
    "    cities_list = information_df.loc[:,[\"city_name\",\"country\"]].reset_index().drop(\"index\",axis=1)\n",
    "    cities_list = cities_list.merge(countries_from_sql,\n",
    "                                    on = \"country\",\n",
    "                                    how = \"left\"\n",
    "                                   )\n",
    "    cities_list = cities_list.drop(\"country\",axis =1)\n",
    "    cities_list.to_sql('cities',\n",
    "                      if_exists='append',\n",
    "                      con=connection_string,\n",
    "                      index=False\n",
    "                      )\n",
    "    \n",
    "    cities_from_sql = get_cities_data(connection_string)\n",
    "    \n",
    "    \n",
    "    information_cities = information_df.merge(cities_from_sql,\n",
    "                         on = \"city_name\",\n",
    "                         how = \"left\"\n",
    "                        )\n",
    "    \n",
    "    information_cities_countries = information_cities.merge(countries_from_sql,\n",
    "                                                            on = \"country\",\n",
    "                                                            how = \"left\"\n",
    "                                                           )\n",
    "    \n",
    "    information_cities_countries = pd.DataFrame(information_cities_countries)\n",
    "    information_cities_countries = information_cities_countries.drop([\"city_name\",\"country\",\"country_id_x\"],axis = 1)\n",
    "    information_cities_countries = information_cities_countries.rename(columns = {\"country_id_y\":\"country_id\"})\n",
    "    \n",
    "    information_cities_countries.to_sql('information',\n",
    "                      if_exists='append',\n",
    "                      con=connection_string,\n",
    "                      index=False,\n",
    "                  )\n",
    "    \n",
    "    weather_df_final = pd.DataFrame()\n",
    "\n",
    "    for city in information_df[\"city_name\"]:\n",
    "        result = weather_request(city)\n",
    "    \n",
    "    # Check if result is not empty before concatenating\n",
    "        if not result.empty:\n",
    "            weather_df_final = pd.concat([weather_df_final, result], ignore_index=True)\n",
    "            \n",
    "    weather_df_final = weather_df_final.merge(cities_from_sql,\n",
    "                                              on = \"city_name\",\n",
    "                                              how = \"left\"\n",
    "                                             )\n",
    "                                              \n",
    "    weather_df_final = weather_df_final.drop(\"city_name\",axis=1)\n",
    "                                              \n",
    "    weather_df_final.to_sql('weather',\n",
    "                      if_exists='append',\n",
    "                      con=connection_string,\n",
    "                      index=False,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73f92590-24d9-4142-bb5d-5b669e7e9223",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def airport_location(latitude_decimal, longitude_decimal):\n",
    "    airport_iata = []\n",
    "    cities = []\n",
    "    url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "\n",
    "    querystring = {\"lat\": str(latitude_decimal), \"lon\": str(longitude_decimal), \"radiusKm\": \"50\", \"limit\": \"10\", \"withFlightInfoOnly\": \"true\"}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4b54815ac4mshe11ca88893efc1ep170ae5jsn49ac4b2d04a5\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        airports = response.json()[\"items\"]\n",
    "\n",
    "        for airport in airports:\n",
    "            airport_iata.append(airport[\"iata\"])\n",
    "            cities.append(airport[\"municipalityName\"])\n",
    "\n",
    "        # Creating a DataFrame\n",
    "        airport_df = pd.DataFrame({\"Airport_IATA\": airport_iata, \"City\": cities})\n",
    "        return airport_df\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09d8cb1b-0585-4e35-af03-147bd17e5740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def airport_schedule(iata_name):\n",
    "    from datetime import datetime, timedelta\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "\n",
    "    tomorrow = (datetime.now().date() + timedelta(days=1)).strftime(\"%Y-%m-%dT\")\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/iata/{iata_name}/{tomorrow}00:00/{tomorrow}11:59\"\n",
    "\n",
    "    querystring = {\"withLeg\": \"true\", \"withCancelled\": \"true\", \"withCodeshared\": \"true\", \"withCargo\": \"true\",\n",
    "                   \"withPrivate\": \"true\", \"withLocation\": \"false\"}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4b54815ac4mshe11ca88893efc1ep170ae5jsn49ac4b2d04a5\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    airport_arrivals = []\n",
    "    iata_names = []  # Corrected variable name\n",
    "    airlines = []\n",
    "    status = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        arrivals = response.json()[\"arrivals\"]\n",
    "\n",
    "        for arrival in arrivals:\n",
    "            # Check if the keys exist before accessing them\n",
    "            if \"arrival\" in arrival and \"scheduledTime\" in arrival[\"arrival\"] and \"local\" in arrival[\"arrival\"][\"scheduledTime\"]:\n",
    "                airport_arrivals.append(arrival[\"arrival\"][\"scheduledTime\"][\"local\"])\n",
    "            else:\n",
    "                airport_arrivals.append(None)\n",
    "\n",
    "            iata_names.append(iata_name)  # Using the corrected variable name iata_names\n",
    "           \n",
    "            if \"airline\" in arrival and \"name\" in arrival[\"airline\"]:\n",
    "                airlines.append(arrival[\"airline\"][\"name\"])\n",
    "            else:\n",
    "                airlines.append(None)\n",
    "                \n",
    "            if \"status\" in arrival:\n",
    "                status.append(arrival[\"status\"])\n",
    "            else:\n",
    "                status.append(None)\n",
    "    else:\n",
    "        airport_arrivals.append(None)\n",
    "        iata_names.append(None)\n",
    "        airlines.append(None)\n",
    "        status.append(None)\n",
    "\n",
    "    return pd.DataFrame({\"airport_arrivals\":airport_arrivals, \"airlines\":airlines, \"iata_name\":iata_names,\"status\":status})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e444b3ba-52f0-4304-9274-25ab9d0036a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1043332848.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    for city in information_df[\"city_name\"]:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def list_airports():\n",
    "    airports_df_final = pd.DataFrame()\n",
    "    airports_df = pd.DataFrame()\n",
    "        for city in information_df[\"city_name\"]:\n",
    "            airports_df = airport_location(information_df.loc[information_df[\"city_name\"]==city,\"latitude\"].values[0],information_df.loc[information_df[\"city_name\"]== city,\"longitude\"].values[0])\n",
    "          # Check if result is not empty before concatenating\n",
    "        if not result.empty:\n",
    "            airports_df_final = pd.concat([airports_df_final, airports_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "8fceb1a6-961d-42e6-b98c-ca77f5b4650f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aux = pd.DataFrame()\n",
    "airport_sheduldes_final = pd.DataFrame()\n",
    "\n",
    "for airport in airports_df_final[\"Airport_IATA\"]:\n",
    "    aux = airport_shedulde(airport)\n",
    "    if not aux.empty:\n",
    "        airport_sheduldes_final = pd.concat([airport_sheduldes_final, aux], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8cab87b9-547b-4505-b863-9f0f31668a28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Now its time to merge the tables and export them to SQL\n",
    "cities_from_sql = pd.read_sql(\"cities\", con=connection())\n",
    "airports_df_final = airports_df_final.merge(cities_from_sql,\n",
    "                        left_on = \"City\",\n",
    "                        right_on = \"city_name\",\n",
    "                        how= \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a44707dd-6d56-4a63-8d1e-dfa44a2cc344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airports_df_final = airports_df_final.drop([\"City\",\"city_name\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "89e1727a-ba29-4331-bd34-88c0ad2a6ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "airports_df_final['city_id'].fillna(np.nan, inplace=True)\n",
    "airports_df_final['country_id'].fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "5611c106-43f6-4412-a385-2bb272c9b55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df_final.to_sql('airports',\n",
    "                      if_exists='append',\n",
    "                      con=connection(),\n",
    "                      index=False,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e4b5e351-f9a0-4556-8ace-b2f2cf89ad06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>Airport_IATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>LBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>ORY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>CDG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>HAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>DTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>CGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BZR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    airport_id  city_id  country_id Airport_IATA\n",
       "0            1      1.0        30.0          BER\n",
       "1            2      3.0        21.0          LBG\n",
       "2            3      3.0        21.0          ORY\n",
       "3            4      3.0        21.0          CDG\n",
       "4            5      4.0        30.0          HAM\n",
       "..         ...      ...         ...          ...\n",
       "65          66     30.0        30.0          DTM\n",
       "66          67     11.0        30.0          CGN\n",
       "67          68     55.0         NaN          MMX\n",
       "68          69      NaN         NaN          CPH\n",
       "69          70      NaN         NaN          BZR\n",
       "\n",
       "[70 rows x 4 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_from_sql = pd.read_sql(\"airports\", con=connection())\n",
    "airports_from_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00a8ddb6-75ff-49aa-9b97-e9261e39b153",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'airport_sheduldes_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Now its necessary to perform the retrieval of the data of airports, merge it with the flights and export it to SQL\u001b[39;00m\n\u001b[0;32m      2\u001b[0m airports_from_sql \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mairports\u001b[39m\u001b[38;5;124m\"\u001b[39m, con\u001b[38;5;241m=\u001b[39mconnection())\n\u001b[1;32m----> 3\u001b[0m airport_sheduldes_final \u001b[38;5;241m=\u001b[39m airport_sheduldes_final\u001b[38;5;241m.\u001b[39mmerge(airports_from_sql,\n\u001b[0;32m      4\u001b[0m                         left_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miata_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m                         right_on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirport_IATA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m                         how\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'airport_sheduldes_final' is not defined"
     ]
    }
   ],
   "source": [
    "#Now its necessary to perform the retrieval of the data of airports, merge it with the flights and export it to SQL\n",
    "airports_from_sql = pd.read_sql(\"airports\", con=connection())\n",
    "airport_sheduldes_final = airport_sheduldes_final.merge(airports_from_sql,\n",
    "                        left_on = \"iata_name\",\n",
    "                        right_on = \"Airport_IATA\",\n",
    "                        how= \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "e0668af1-eeb2-4b02-8321-21a4fbc5c620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_sheduldes_final = airport_sheduldes_final.drop([\"iata_name\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "0600e6f2-93ad-4532-bbc4-6a0794be5684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming \"airport_arrivals\" is the column containing datetime-like strings\n",
    "airport_sheduldes_final['airport_arrivals'] = pd.to_datetime(airport_sheduldes_final['airport_arrivals'], utc=True)\n",
    "\n",
    "# Format the datetime column as a string in the desired format\n",
    "airport_sheduldes_final['airport_arrivals'] = airport_sheduldes_final['airport_arrivals'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "d4fdd5eb-5612-4252-bcc8-aa693cd2c7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_sheduldes_final = airport_sheduldes_final.drop(\"Airport_IATA\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "ba9f4d59-e49d-45d4-b74d-01fab5d76c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_sheduldes_final.rename(columns = {\"status\":\"status_\"},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "353981ef-7b02-431d-8cca-d6ed3f9cfff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport_sheduldes_final = airport_sheduldes_final.to_sql(\"airport_sheduldes\",\n",
    "                                                         if_exists='append',\n",
    "                                                        con=connection(),\n",
    "                                                        index=False,\n",
    "                                                                   )\n",
    "                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac8660-19db-4196-a455-49a51d032d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
