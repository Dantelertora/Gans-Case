{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609bbc75-536b-4eb6-92ab-6090bae4f780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\lertora\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lertora\\anaconda3\\lib\\site-packages (from sqlalchemy) (2.0.1)\n",
      "Requirement already satisfied: pymysql in c:\\users\\lertora\\anaconda3\\lib\\site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy\n",
    "!pip install pymysql\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3bb5d1-753d-4607-a81e-f531fbb770c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extracting a list of the biggest European cities\n",
    "def list_cities():\n",
    "    url_loop = \"https://en.wikipedia.org/wiki/List_of_cities_in_the_European_Union_by_population_within_city_limits\"\n",
    "    response = requests.get(url_loop)\n",
    "    original_soup_cities = BeautifulSoup(response.content, 'html.parser')\n",
    "    side_table_cities = original_soup_cities.find(\"tbody\")\n",
    "    list_cities = side_table_cities.find_all(width=\"23\")\n",
    "    list_cities_extract = []\n",
    "    for i in range(len(list_cities)):\n",
    "        list_cities_extract.append(list_cities[i].find_previous(\"a\").get_text())\n",
    "    return list_cities_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb046db-c0be-44cc-9939-8ce7226ab8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Cities : Function for Web Scraping population, latitude, country\n",
    "def cities(example):\n",
    "    city_name = []\n",
    "    population = []\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    country = []\n",
    "    date_forecast = []\n",
    "    temperature = []\n",
    "    forecast = []\n",
    "    rain_in_last_3h = []\n",
    "    wind_speed = []\n",
    "\n",
    "    \"\"\"\n",
    "    Scrapes information from Wikipedia about a city and appends the data to global lists.\n",
    "\n",
    "    Parameters:\n",
    "    - example (str): The name of the city to fetch information for.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Global Lists Modified:\n",
    "    - city_name (list): List of city names.\n",
    "    - population (list): List of city populations.\n",
    "    - latitude (list): List of city latitudes.\n",
    "    - longitude (list): List of city longitudes.\n",
    "    - country (list): List of city countries.\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace spaces with underscores in the city name for constructing the Wikipedia URL\n",
    "    example = example.replace(\" \", \"_\")\n",
    "\n",
    "    # Construct the Wikipedia URL for the city\n",
    "    url_loop = f\"https://en.wikipedia.org/wiki/{example}\"\n",
    "\n",
    "    # Make a request to the Wikipedia page\n",
    "    response = requests.get(url_loop)\n",
    "\n",
    "    # Parse the HTML content of the Wikipedia page\n",
    "    original_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract information from the infobox if it exists on the Wikipedia page\n",
    "    side_table = original_soup.find(\"table\", class_=\"infobox ib-settlement vcard\")\n",
    "\n",
    "    if side_table:\n",
    "        # Extract population information\n",
    "        population_value = side_table.find(string=re.compile(\"population\", re.IGNORECASE))\n",
    "        try:\n",
    "            population.append(int(population_value.find_next(\"td\").get_text().replace(\",\", \"\")) if population_value else None)\n",
    "        except (ValueError, AttributeError):\n",
    "            population.append(None)\n",
    "\n",
    "        # Extract latitude information\n",
    "        latitude_value = side_table.find(class_=\"latitude\")\n",
    "        latitude.append(latitude_value.get_text() if latitude_value else None)\n",
    "        \n",
    "        # Extract longitude information\n",
    "        longitude_value = side_table.find(class_=\"longitude\")\n",
    "        longitude.append(longitude_value.get_text() if longitude_value else None)\n",
    "\n",
    "        # Extract country information\n",
    "        country_value = side_table.find(string=re.compile(\"country\", re.IGNORECASE))\n",
    "        country.append(country_value.find_next(\"td\").get_text() if country_value else None)\n",
    "        \n",
    "    else:\n",
    "        # If the table is not found, set NaN values for all fields\n",
    "        population.append(None)\n",
    "        latitude.append(None)\n",
    "        longitude.append(None)\n",
    "        country.append(None)\n",
    "        \n",
    "    city_name.append(example)\n",
    "    \n",
    "    information_city = pd.DataFrame({\n",
    "        \"city_name\": city_name,\n",
    "        \"population\": population,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"country\": country\n",
    "    })\n",
    "    \n",
    "    return information_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f49d263-33e4-4bb0-bd3f-12acc77c74c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dms_to_dd(coord_str):\n",
    "    # Regular expression to extract degrees, optional minutes, and optional seconds\n",
    "    pattern = re.compile(r'(\\d+)°\\s*(?:(\\d+)′)?\\s*(?:(\\d+)″)?')\n",
    "    match = pattern.match(coord_str)\n",
    "\n",
    "    if match:\n",
    "        degrees, minutes, seconds = map(int, match.groups(default='0'))\n",
    "        dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "\n",
    "        return dd\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid coordinate format: {coord_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5836df6e-0f5b-43ed-a96e-db498b9e0df0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def country_cars():\n",
    "    url_loop = \"https://en.wikipedia.org/wiki/List_of_countries_by_vehicles_per_capita\"\n",
    "\n",
    "    response = requests.get(url_loop)\n",
    "\n",
    "    original_soup_autos = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Limiting data to the Y-Axis\n",
    "    side_table_autos = original_soup_autos.find(\"tbody\")\n",
    "    \n",
    "    list_countries = side_table_autos.find_all(\"span\", class_=\"flagicon\")\n",
    "    \n",
    "    # Creating list of countries and amount of vehicles\n",
    "    list_countries_extract = []\n",
    "    list_countries_extract_autos = []\n",
    "    \n",
    "    for i in range(len(list_countries)):\n",
    "        list_countries_extract.append(list_countries[i].find_next(\"a\").get_text())\n",
    "        list_countries_extract_autos.append(list_countries[i].find_next(\"td\").find_next(\"td\").get_text())\n",
    "    \n",
    "    for n in range(len(list_countries_extract_autos)):\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\",\", \"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"\\n\", \"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"[\", \"\")\n",
    "        list_countries_extract_autos[n] = list_countries_extract_autos[n].replace(\"]\", \"\")\n",
    "        list_countries_extract_autos[n] = int(list_countries_extract_autos[n])\n",
    "        \n",
    "    countries_df = pd.DataFrame({\"country\": list_countries_extract, \"cars\": list_countries_extract_autos})\n",
    "    return countries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b68c4c0-658f-4cdd-a727-e70eecccb31d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weather_request(example, information_df):\n",
    "    berlin_timezone = timezone('Europe/Berlin')\n",
    "    retrieval_time = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    weather_items = []\n",
    "    latitude = information_df.loc[information_df[\"city_name\"] == example, \"latitude\"].values[0]\n",
    "    longitude = information_df.loc[information_df[\"city_name\"] == example, \"longitude\"].values[0]\n",
    "\n",
    "    # Construct the API request URL\n",
    "    url_map = f\"http://api.openweathermap.org/data/2.5/weather?lat={latitude}&lon={longitude}&appid=4bcaab846859609d453e249b3b3f0a16\"\n",
    "    \n",
    "    # Make the API request and handle potential errors\n",
    "    try:\n",
    "        city_id_openweather = requests.get(url_map)\n",
    "        city_id_openweather.raise_for_status()  # Raise an error for bad responses (non-2xx status codes)\n",
    "        city_id_openweather = city_id_openweather.json()\n",
    "        city_id_openweather = city_id_openweather[\"id\"]\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle request exceptions (e.g., network issues, API errors)\n",
    "        print(f\"Error in request for latitude {latitude}, longitude {longitude}: {e}\")\n",
    "        temperature_request = None  # Append None for temperature to indicate an error\n",
    "        sky_request = None  # Append None for sky description to indicate an error\n",
    "    \n",
    "    url = f\"http://api.openweathermap.org/data/2.5/forecast?id={city_id_openweather}&appid=4bcaab846859609d453e249b3b3f0a16\"\n",
    " \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    response = response.json()\n",
    "    \n",
    "    for item in response[\"list\"]:\n",
    "        weather_item = {\n",
    "            \"city_name\" : example,\n",
    "            \"forecast_time\": item.get(\"dt_txt\", None),\n",
    "            \"temperature\": item[\"main\"].get(\"temp\", None),\n",
    "            \"forecast\": item[\"weather\"][0].get(\"main\", None),\n",
    "            \"rain_in_last_3h\": item.get(\"rain\", {}).get(\"3h\", 0),\n",
    "            \"wind_speed\": item[\"wind\"].get(\"speed\", None),\n",
    "            \"retrieval_time\" : retrieval_time\n",
    "        }\n",
    "        \n",
    "        weather_items.append(weather_item)\n",
    "        weather_df = pd.DataFrame(weather_items)\n",
    "    return weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2bd7806-9f9b-4559-9cd3-17788c3e872f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def airport_location(latitude_decimal, longitude_decimal):\n",
    "    airport_iata = []\n",
    "    cities = []\n",
    "    url = \"https://aerodatabox.p.rapidapi.com/airports/search/location\"\n",
    "\n",
    "    querystring = {\"lat\": str(latitude_decimal), \"lon\": str(longitude_decimal), \"radiusKm\": \"50\", \"limit\": \"10\", \"withFlightInfoOnly\": \"true\"}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4b54815ac4mshe11ca88893efc1ep170ae5jsn49ac4b2d04a5\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        airports = response.json()[\"items\"]\n",
    "\n",
    "        for airport in airports:\n",
    "            airport_iata.append(airport[\"iata\"])\n",
    "            city_name = airport.get(\"municipalityName\", None)\n",
    "            cities.append(city_name)\n",
    "    else:\n",
    "        airport_iata.append(None)\n",
    "        cities.append(None)\n",
    "            \n",
    "     # Creating a DataFrame\n",
    "    airport_df = pd.DataFrame({\"Airport_IATA\": airport_iata, \"City\": cities})\n",
    "    return airport_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75faf9b1-a7c2-4304-9c69-ce160eb1530d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def airport_schedule(iata_name):\n",
    "    from datetime import datetime, timedelta\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    tomorrow = (datetime.now().date() + timedelta(days=1)).strftime(\"%Y-%m-%dT\")\n",
    "    url = f\"https://aerodatabox.p.rapidapi.com/flights/airports/iata/{iata_name}/{tomorrow}00:00/{tomorrow}11:59\"\n",
    "\n",
    "    querystring = {\"withLeg\": \"true\", \"withCancelled\": \"true\", \"withCodeshared\": \"true\", \"withCargo\": \"true\",\n",
    "                   \"withPrivate\": \"true\", \"withLocation\": \"false\"}\n",
    "\n",
    "    headers = {\n",
    "        \"X-RapidAPI-Key\": \"4b54815ac4mshe11ca88893efc1ep170ae5jsn49ac4b2d04a5\",\n",
    "        \"X-RapidAPI-Host\": \"aerodatabox.p.rapidapi.com\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    airport_arrivals = []\n",
    "    iata_names = []  # Corrected variable name\n",
    "    airlines = []\n",
    "    status = []\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        arrivals = response.json()[\"arrivals\"]\n",
    "\n",
    "        for arrival in arrivals:\n",
    "            # Check if the keys exist before accessing them\n",
    "            if \"arrival\" in arrival and \"scheduledTime\" in arrival[\"arrival\"] and \"local\" in arrival[\"arrival\"][\"scheduledTime\"]:\n",
    "                airport_arrivals.append(arrival[\"arrival\"][\"scheduledTime\"][\"local\"])\n",
    "            else:\n",
    "                airport_arrivals.append(None)\n",
    "\n",
    "            iata_names.append(iata_name)  # Using the corrected variable name iata_names\n",
    "           \n",
    "            if \"airline\" in arrival and \"name\" in arrival[\"airline\"]:\n",
    "                airlines.append(arrival[\"airline\"][\"name\"])\n",
    "            else:\n",
    "                airlines.append(None)\n",
    "                \n",
    "            if \"status\" in arrival:\n",
    "                status.append(arrival[\"status\"])\n",
    "            else:\n",
    "                status.append(None)\n",
    "    else:\n",
    "        airport_arrivals.append(None)\n",
    "        iata_names.append(None)\n",
    "        airlines.append(None)\n",
    "        status.append(None)\n",
    "        \n",
    "    airport_schedule_df = pd.DataFrame({\"airport_arrivals\": airport_arrivals, \"airlines\": airlines, \"iata_name\": iata_names, \"status\": status})\n",
    "    return airport_schedule_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3edfc60-ab15-4737-8a2e-93d97423d361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def connection():\n",
    "    schema = \"gans\"\n",
    "    host = \"127.0.0.1\"\n",
    "    user = \"root\"\n",
    "    password = \"Riverplate121.\"\n",
    "    port = 3306\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ad7096-0c8b-4fc8-8297-6602406fd87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cities_data(connection_string):\n",
    "    return pd.read_sql(\"cities\", con=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee918e14-cbab-45ba-84c8-2e78335c66c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_countries_data(connection_string):\n",
    "    return pd.read_sql(\"countries\", con=connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56d7e827-9ec3-4280-9fd8-faffc65c904f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_tables_sql():\n",
    "    from sqlalchemy import create_engine\n",
    "    # Connect to MySQL server\n",
    "    engine = create_engine(connection())\n",
    "\n",
    "    # Drop and recreate the database\n",
    "    engine.execute(\"DROP DATABASE IF EXISTS gans;\")\n",
    "    engine.execute(\"CREATE DATABASE gans;\")\n",
    "    engine.execute(\"USE gans;\")\n",
    "\n",
    "    # Create tables\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE countries (\n",
    "            country_id INT AUTO_INCREMENT,\n",
    "            country VARCHAR(225),\n",
    "            PRIMARY KEY (country_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE cars (\n",
    "            cars INT,\n",
    "            country_id INT,\n",
    "            FOREIGN KEY (country_id) REFERENCES countries(country_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE cities (\n",
    "            city_id INT AUTO_INCREMENT,\n",
    "            city_name VARCHAR(255),\n",
    "            country_id INT,\n",
    "            PRIMARY KEY (city_id),\n",
    "            FOREIGN KEY (country_id) REFERENCES countries(country_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE information (\n",
    "            population INT,\n",
    "            latitude FLOAT,\n",
    "            longitude FLOAT,\n",
    "            city_id INT,\n",
    "            country_id INT,\n",
    "            FOREIGN KEY (city_id) REFERENCES cities(city_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE weather (\n",
    "            city_id INT,\n",
    "            country_id INT,\n",
    "            forecast_time DATE,\n",
    "            temperature FLOAT,\n",
    "            forecast VARCHAR(255),\n",
    "            rain_in_last_3h FLOAT,\n",
    "            wind_speed FLOAT,\n",
    "            retrieval_time DATE,\n",
    "            FOREIGN KEY (city_id) REFERENCES cities(city_id),\n",
    "            FOREIGN KEY (country_id) REFERENCES countries(country_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE airports (\n",
    "            airport_id INT AUTO_INCREMENT,\n",
    "            city_id INT,\n",
    "            country_id INT,\n",
    "            Airport_IATA VARCHAR(3),\n",
    "            PRIMARY KEY (airport_id),\n",
    "            FOREIGN KEY (city_id) REFERENCES cities(city_id),\n",
    "            FOREIGN KEY (country_id) REFERENCES countries(country_id)\n",
    "        );\n",
    "    \"\"\")\n",
    "\n",
    "    engine.execute(\"\"\"\n",
    "        CREATE TABLE airport_sheduldes (\n",
    "            airport_arrivals DATETIME,\n",
    "            airlines VARCHAR(255),\n",
    "            status_ VARCHAR(255),\n",
    "            airport_id INT,\n",
    "            city_id INT,\n",
    "            country_id INT,\n",
    "            FOREIGN KEY (airport_id) REFERENCES airports(airport_id),\n",
    "            FOREIGN KEY (city_id) REFERENCES cities(city_id),\n",
    "            FOREIGN KEY (country_id) REFERENCES countries(country_id)\n",
    "        );\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0749be37-8a82-4484-87c0-1695623c3d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update():\n",
    "    ####################################################---Extract---#####################################################\n",
    "    list_cities_extract = list_cities()\n",
    "    information_df = pd.DataFrame()\n",
    "    for i in list_cities_extract:\n",
    "        information_city = cities(i)\n",
    "        information_df = pd.concat([information_df, information_city], ignore_index=True)\n",
    "\n",
    "    # Removing null values\n",
    "    information_df = information_df.loc[\n",
    "        information_df[\"population\"].notnull() & information_df[\"latitude\"].notnull() & information_df[\n",
    "            \"longitude\"].notnull(), :]\n",
    "\n",
    "    # Converting latitude and longitude into decimal\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    for i in information_df[\"latitude\"]:\n",
    "        latitudes.append(dms_to_dd(i))\n",
    "    for n in information_df[\"longitude\"]:\n",
    "        longitudes.append(dms_to_dd(n))\n",
    "\n",
    "    information_df[\"latitude\"] = latitudes\n",
    "    information_df[\"longitude\"] = longitudes\n",
    "\n",
    "    localizacion = pd.DataFrame({\"latitudes\": latitudes, \"longitudes\": longitudes})\n",
    "\n",
    "    weather_df_final = pd.DataFrame()\n",
    "    for city in information_df[\"city_name\"]:\n",
    "        weather_city = weather_request(city, information_df)\n",
    "        weather_df_final = pd.concat([weather_df_final, weather_city], ignore_index=True)\n",
    "\n",
    "    airports_final = pd.DataFrame()\n",
    "    for index, row in localizacion.iterrows():\n",
    "        airport_city = airport_location(row[\"latitudes\"], row[\"longitudes\"])\n",
    "        airports_final = pd.concat([airports_final, airport_city], ignore_index=True)\n",
    "\n",
    "    airport_shedulde_final = pd.DataFrame()\n",
    "    for iata_name in airports_final[\"Airport_IATA\"]:\n",
    "        airport_shedulde_city = airport_schedule(iata_name)\n",
    "        airport_shedulde_final = pd.concat([airport_shedulde_final, airport_shedulde_city], ignore_index=True)\n",
    "\n",
    "    country_final = country_cars()\n",
    "\n",
    "    ####################################################---Transform & STORE---#####################################################\n",
    "\n",
    "    clean_tables_sql()\n",
    "    \n",
    "    ##################   COUNTRIES\n",
    "    countries_for_sql = country_final.drop(\"cars\", axis=1)\n",
    "    countries_for_sql.to_sql('countries',\n",
    "                             if_exists='append',\n",
    "                             con=connection(),\n",
    "                             index=False,\n",
    "                             )\n",
    "    countries_from_sql = pd.read_sql(\"countries\", con=connection())\n",
    "\n",
    "    ################   CARS\n",
    "    cars_for_sql = countries_from_sql.merge(country_final,\n",
    "                                             on=\"country\",\n",
    "                                             how=\"left\",\n",
    "                                             ).drop(\"country\", axis=1)\n",
    "\n",
    "    cars_for_sql.to_sql('cars',\n",
    "                        if_exists='append',\n",
    "                        con=connection(),\n",
    "                        index=False,\n",
    "                        )\n",
    "\n",
    "    ################   CITIES\n",
    "    cities_for_sql = information_df.loc[:, [\"city_name\", \"country\"]]\n",
    "\n",
    "    cities_for_sql = cities_for_sql.merge(countries_from_sql,\n",
    "                                          on=\"country\",\n",
    "                                          how=\"left\"\n",
    "                                          )\n",
    "    \n",
    "    cities_for_sql = cities_for_sql.drop(\"country\",axis = 1)\n",
    "\n",
    "    cities_for_sql = cities_for_sql.loc[~cities_for_sql[\"country_id\"].isnull(), :]\n",
    "    cities_for_sql[\"country_id\"] = pd.to_numeric(cities_for_sql[\"country_id\"], errors='coerce')\n",
    "    cities_for_sql.loc[:, \"country_id\"] = cities_for_sql[\"country_id\"].dropna().astype(int)\n",
    "\n",
    "    cities_for_sql.to_sql('cities',\n",
    "                          if_exists='append',\n",
    "                          con=connection(),\n",
    "                          index=False,\n",
    "                          )\n",
    "\n",
    "    cities_from_sql = pd.read_sql(\"cities\", con=connection())\n",
    "\n",
    "    ################ INFORMATION\n",
    "    information_final = information_df.merge(cities_from_sql,\n",
    "                                             on=\"city_name\",\n",
    "                                             how=\"inner\").drop([\"city_name\", \"country\"], axis=1)\n",
    "\n",
    "    information_final.to_sql('information',\n",
    "                             if_exists='append',\n",
    "                             con=connection(),\n",
    "                             index=False,\n",
    "                             )\n",
    "\n",
    "    ################ WEATHER\n",
    "    weather_df_final = weather_df_final.merge(cities_from_sql,\n",
    "                                              on=\"city_name\",\n",
    "                                              how=\"inner\").drop(\"city_name\", axis=1)\n",
    "\n",
    "    weather_df_final.to_sql('weather',\n",
    "                            if_exists='append',\n",
    "                            con=connection(),\n",
    "                            index=False,\n",
    "                            )\n",
    "\n",
    "    ################ AIRPORTS\n",
    "    airports_final = airports_final.merge(cities_from_sql,\n",
    "                                          right_on=\"city_name\",\n",
    "                                          left_on=\"City\",\n",
    "                                          how=\"inner\").drop([\"City\", \"city_name\"], axis=1)\n",
    "\n",
    "    airports_final = airports_final.drop_duplicates()\n",
    "\n",
    "    airports_final.to_sql('airports',\n",
    "                          if_exists='append',\n",
    "                          con=connection(),\n",
    "                          index=False,\n",
    "                          )\n",
    "\n",
    "    airports_from_sql = pd.read_sql(\"airports\", con=connection())\n",
    "\n",
    "    ################ AIRPORTS  SHEDULDES\n",
    "\n",
    "    airport_shedulde_final = airport_shedulde_final.merge(airports_from_sql,\n",
    "                                                           right_on=\"Airport_IATA\",\n",
    "                                                           left_on=\"iata_name\",\n",
    "                                                           how=\"inner\"\n",
    "                                                           ).drop([\"iata_name\", \"Airport_IATA\"], axis=1).rename(\n",
    "        columns={\"status\": \"status_\"})\n",
    "\n",
    "    airport_shedulde_final['airport_arrivals'] = pd.to_datetime(airport_shedulde_final['airport_arrivals'], utc=True)\n",
    "\n",
    "    # Format the datetime column as a string in the desired format\n",
    "    airport_shedulde_final['airport_arrivals'] = airport_shedulde_final['airport_arrivals'].dt.strftime(\n",
    "        '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    airport_shedulde_final.to_sql('airport_sheduldes',\n",
    "                                  if_exists='append',\n",
    "                                  con=connection(),\n",
    "                                  index=False,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6326cb8f-3210-4371-86b4-be200bbe02d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c044470c-f943-46ba-8431-ee5099def663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_arrivals</th>\n",
       "      <th>airlines</th>\n",
       "      <th>iata_name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-16 06:50+01:00</td>\n",
       "      <td>Qatar Airways</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>Aegean</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>Eurowings</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-16 07:35+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>Air Serbia</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>airBaltic</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-01-16 07:55+01:00</td>\n",
       "      <td>United</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-01-16 07:45+01:00</td>\n",
       "      <td>Wizz Air</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-01-16 07:50+01:00</td>\n",
       "      <td>Wizz Air</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-01-16 08:00+01:00</td>\n",
       "      <td>Finnair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-01-16 08:05+01:00</td>\n",
       "      <td>Danish Air</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-01-16 08:10+01:00</td>\n",
       "      <td>Eurowings</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-01-16 08:30+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-01-16 08:55+01:00</td>\n",
       "      <td>AZAL Azerbaijan</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-01-16 08:55+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-01-16 08:10+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-01-16 08:45+01:00</td>\n",
       "      <td>SWISS</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-01-16 08:25+01:00</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-01-16 09:20+01:00</td>\n",
       "      <td>Air France</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-01-16 09:40+01:00</td>\n",
       "      <td>Aer Lingus</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-01-16 09:55+01:00</td>\n",
       "      <td>Eurowings</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-01-16 09:25+01:00</td>\n",
       "      <td>KLM</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-01-16 09:55+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2024-01-16 09:30+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2024-01-16 09:45+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2024-01-16 09:10+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2024-01-16 09:25+01:00</td>\n",
       "      <td>El Al</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2024-01-16 09:45+01:00</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2024-01-16 10:45+01:00</td>\n",
       "      <td>Aegean</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2024-01-16 10:10+01:00</td>\n",
       "      <td>British Airways</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2024-01-16 10:00+01:00</td>\n",
       "      <td>Eurowings</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024-01-16 10:05+01:00</td>\n",
       "      <td>Eurowings</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024-01-16 10:55+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024-01-16 10:55+01:00</td>\n",
       "      <td>Iberia Express</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024-01-16 10:55+01:00</td>\n",
       "      <td>Iberia</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024-01-16 10:55+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024-01-16 10:00+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024-01-16 10:35+01:00</td>\n",
       "      <td>LOT - Polish</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024-01-16 10:00+01:00</td>\n",
       "      <td>SWISS</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2024-01-16 10:35+01:00</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2024-01-16 10:55+01:00</td>\n",
       "      <td>Pegasus</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2024-01-16 10:00+01:00</td>\n",
       "      <td>Vueling</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2024-01-16 11:30+01:00</td>\n",
       "      <td>Air France</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2024-01-16 11:05+01:00</td>\n",
       "      <td>British Airways</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2024-01-16 11:20+01:00</td>\n",
       "      <td>British Airways</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2024-01-16 11:55+01:00</td>\n",
       "      <td>Ryanair</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2024-01-16 11:55+01:00</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2024-01-16 11:05+01:00</td>\n",
       "      <td>KLM</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2024-01-16 11:05+01:00</td>\n",
       "      <td>SAS</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2024-01-16 11:05+01:00</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>BER</td>\n",
       "      <td>Expected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          airport_arrivals         airlines iata_name    status\n",
       "0   2024-01-16 06:50+01:00    Qatar Airways       BER  Expected\n",
       "1   2024-01-16 07:55+01:00           Aegean       BER  Expected\n",
       "2   2024-01-16 07:55+01:00        Eurowings       BER  Expected\n",
       "3   2024-01-16 07:35+01:00          Ryanair       BER  Expected\n",
       "4   2024-01-16 07:55+01:00       Air Serbia       BER  Expected\n",
       "5   2024-01-16 07:55+01:00        Lufthansa       BER  Expected\n",
       "6   2024-01-16 07:55+01:00        airBaltic       BER  Expected\n",
       "7   2024-01-16 07:55+01:00           United       BER  Expected\n",
       "8   2024-01-16 07:45+01:00         Wizz Air       BER  Expected\n",
       "9   2024-01-16 07:50+01:00         Wizz Air       BER  Expected\n",
       "10  2024-01-16 08:00+01:00          Finnair       BER  Expected\n",
       "11  2024-01-16 08:05+01:00       Danish Air       BER  Expected\n",
       "12  2024-01-16 08:10+01:00        Eurowings       BER  Expected\n",
       "13  2024-01-16 08:30+01:00          Ryanair       BER  Expected\n",
       "14  2024-01-16 08:55+01:00  AZAL Azerbaijan       BER  Expected\n",
       "15  2024-01-16 08:55+01:00        Lufthansa       BER  Expected\n",
       "16  2024-01-16 08:10+01:00        Lufthansa       BER  Expected\n",
       "17  2024-01-16 08:45+01:00            SWISS       BER  Expected\n",
       "18  2024-01-16 08:25+01:00         Austrian       BER  Expected\n",
       "19  2024-01-16 09:20+01:00       Air France       BER  Expected\n",
       "20  2024-01-16 09:40+01:00       Aer Lingus       BER  Expected\n",
       "21  2024-01-16 09:55+01:00        Eurowings       BER  Expected\n",
       "22  2024-01-16 09:25+01:00              KLM       BER  Expected\n",
       "23  2024-01-16 09:55+01:00        Lufthansa       BER  Expected\n",
       "24  2024-01-16 09:30+01:00          Ryanair       BER  Expected\n",
       "25  2024-01-16 09:45+01:00          Ryanair       BER  Expected\n",
       "26  2024-01-16 09:10+01:00        Lufthansa       BER  Expected\n",
       "27  2024-01-16 09:25+01:00            El Al       BER  Expected\n",
       "28  2024-01-16 09:45+01:00          Turkish       BER  Expected\n",
       "29  2024-01-16 10:45+01:00           Aegean       BER  Expected\n",
       "30  2024-01-16 10:10+01:00  British Airways       BER  Expected\n",
       "31  2024-01-16 10:00+01:00        Eurowings       BER  Expected\n",
       "32  2024-01-16 10:05+01:00        Eurowings       BER  Expected\n",
       "33  2024-01-16 10:55+01:00          Ryanair       BER  Expected\n",
       "34  2024-01-16 10:55+01:00   Iberia Express       BER  Expected\n",
       "35  2024-01-16 10:55+01:00           Iberia       BER  Expected\n",
       "36  2024-01-16 10:55+01:00        Lufthansa       BER  Expected\n",
       "37  2024-01-16 10:00+01:00        Lufthansa       BER  Expected\n",
       "38  2024-01-16 10:35+01:00     LOT - Polish       BER  Expected\n",
       "39  2024-01-16 10:00+01:00            SWISS       BER  Expected\n",
       "40  2024-01-16 10:35+01:00         Austrian       BER  Expected\n",
       "41  2024-01-16 10:55+01:00          Pegasus       BER  Expected\n",
       "42  2024-01-16 10:00+01:00          Vueling       BER  Expected\n",
       "43  2024-01-16 11:30+01:00       Air France       BER  Expected\n",
       "44  2024-01-16 11:05+01:00  British Airways       BER  Expected\n",
       "45  2024-01-16 11:20+01:00  British Airways       BER  Expected\n",
       "46  2024-01-16 11:55+01:00          Ryanair       BER  Expected\n",
       "47  2024-01-16 11:55+01:00        Lufthansa       BER  Expected\n",
       "48  2024-01-16 11:05+01:00              KLM       BER  Expected\n",
       "49  2024-01-16 11:05+01:00              SAS       BER  Expected\n",
       "50  2024-01-16 11:05+01:00         Brussels       BER  Expected"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_schedule(\"BER\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
